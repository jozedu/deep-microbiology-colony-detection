{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7296b8b1",
   "metadata": {},
   "source": [
    "# 2. Data Exploration & Registration\n",
    "\n",
    "This notebook handles:\n",
    "- Loading and registering COCO-format datasets with Detectron2.\n",
    "- Exploring dataset statistics (categories, image counts, annotation distribution).\n",
    "- Visualizing annotated samples.\n",
    "\n",
    "**Prerequisites:** Run `1_setup.ipynb` first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f0c1c",
   "metadata": {},
   "source": [
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import config\n",
    "from utils.visualization import show_dataset_samples, show_specific_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82456eef",
   "metadata": {},
   "source": [
    "## 2.2 Choose Dataset\n",
    "\n",
    "Select which dataset to explore by setting `DATASET_SOURCE` and `SUBSET`.\n",
    "\n",
    "**Part 1 (AGAR):** `DATASET_SOURCE = 'agar'`, `SUBSET` âˆˆ `{'total', 'bright', 'dark', 'vague', 'lowres'}`\n",
    "\n",
    "**Part 2 (Curated):** `DATASET_SOURCE = 'roboflow'`, download dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== CONFIGURE HERE =====================\n",
    "DATASET_SOURCE = \"agar\"      # 'agar' or 'roboflow'\n",
    "SUBSET = \"total\"             # For AGAR: 'total', 'bright', 'dark', 'vague', 'lowres'\n",
    "# =========================================================\n",
    "\n",
    "if DATASET_SOURCE == \"agar\":\n",
    "    dataset = config.AGAR_DATASETS[SUBSET]\n",
    "    img_dir = config.AGAR_IMG_DIR\n",
    "    train_path, val_path, test_path = dataset[\"train\"], dataset[\"val\"], dataset[\"test\"]\n",
    "    img_dir_train = img_dir_val = img_dir_test = img_dir\n",
    "    train_name = f\"{SUBSET}_train\"\n",
    "    val_name = f\"{SUBSET}_val\"\n",
    "    test_name = f\"{SUBSET}_test\"\n",
    "\n",
    "elif DATASET_SOURCE == \"roboflow\":\n",
    "    # Download Roboflow dataset (run once)\n",
    "    # !curl -L \"{config.ROBOFLOW_DOWNLOAD_URL}\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "    dataset = config.ROBOFLOW_DATASETS[\"curated\"]\n",
    "    train_path = dataset[\"train\"]\n",
    "    val_path = dataset[\"val\"]\n",
    "    test_path = dataset[\"test\"]\n",
    "    img_dir_train = dataset[\"train_dir\"]\n",
    "    img_dir_val = dataset[\"val_dir\"]\n",
    "    img_dir_test = dataset[\"test_dir\"]\n",
    "    train_name = \"robo_train\"\n",
    "    val_name = \"robo_val\"\n",
    "    test_name = \"robo_test\"\n",
    "\n",
    "print(f\"Dataset: {DATASET_SOURCE} / {SUBSET if DATASET_SOURCE == 'agar' else 'curated'}\")\n",
    "print(f\"Train: {train_path}\")\n",
    "print(f\"Val:   {val_path}\")\n",
    "print(f\"Test:  {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d97ab5",
   "metadata": {},
   "source": [
    "## 2.3 Register Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2834fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register datasets with Detectron2 (safe to re-run)\n",
    "for name in [train_name, val_name, test_name]:\n",
    "    if name in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(name)\n",
    "        MetadataCatalog.remove(name)\n",
    "\n",
    "register_coco_instances(train_name, {}, train_path, img_dir_train)\n",
    "register_coco_instances(val_name, {}, val_path, img_dir_val)\n",
    "register_coco_instances(test_name, {}, test_path, img_dir_test)\n",
    "\n",
    "print(f\"Registered: {train_name}, {val_name}, {test_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33eff2",
   "metadata": {},
   "source": [
    "## 2.4 Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Categories:\", data['categories'])\n",
    "print(f\"Number of training images: {len(data['images'])}\")\n",
    "print(f\"Number of annotations: {len(data['annotations'])}\")\n",
    "\n",
    "# Class distribution\n",
    "from collections import Counter\n",
    "class_counts = Counter(ann['category_id'] for ann in data['annotations'])\n",
    "cat_names = {c['id']: c['name'] for c in data['categories']}\n",
    "print(\"\\nClass distribution:\")\n",
    "for cat_id, count in sorted(class_counts.items()):\n",
    "    name = cat_names.get(cat_id, f\"class_{cat_id}\")\n",
    "    print(f\"  {name}: {count} ({100*count/len(data['annotations']):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3a5b4",
   "metadata": {},
   "source": [
    "## 2.5 Visualize Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac83ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataset_samples(train_name, num_samples=5, scale=0.5, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7d6db",
   "metadata": {},
   "source": [
    "## 2.6 Visualize a Specific Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the filename to inspect a specific image\n",
    "# show_specific_image(train_name, \"429.jpg\", img_dir_train, scale=0.5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
