{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab137a0",
   "metadata": {},
   "source": [
    "# 9 ‚Äî Batch Inference (Standardized Test-Set Predictions)\n",
    "\n",
    "**Purpose:** Run standardized inference on the **test set** for all trained models,\n",
    "saving `coco_instances_results.json` consistently to each model's output directory.\n",
    "\n",
    "This is a **prerequisite** for:\n",
    "- Bootstrap confidence intervals (notebook 8)\n",
    "- Multi-threshold evaluation (notebook 8)\n",
    "- Filter sensitivity analysis\n",
    "\n",
    "**What it does:**\n",
    "1. Iterates over all trained AGAR + Roboflow models in `config.py`\n",
    "2. Loads each `model_final.pth`\n",
    "3. Runs inference on the corresponding test set\n",
    "4. Saves predictions to `{model_dir}/test/coco_instances_results.json`\n",
    "\n",
    "**Run on:** Google Colab with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Mount Google Drive (for data and model weights)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Clone project repo (code, config, utils)\n",
    "REPO_URL = \"https://github.com/jozedu/deep-microbiology-colony-detection.git\"\n",
    "REPO_DIR = \"/content/deep-microbiology-colony-detection\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install detectron2 if needed\n",
    "try:\n",
    "    import detectron2\n",
    "except ImportError:\n",
    "    !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "import config\n",
    "from config import (\n",
    "    AGAR_IMG_DIR, OUTPUTS_DIR, MODELS,\n",
    "    AGAR_DATASETS, AGAR_TRAINED_MODELS,\n",
    "    ROBOFLOW_DATASETS, ROBOFLOW_TRAINED_MODELS,\n",
    "    is_retinanet,\n",
    ")\n",
    "\n",
    "print(f\"Detectron2 version: {detectron2.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bf75f",
   "metadata": {},
   "source": [
    "## Register all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8621c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Register AGAR datasets ‚îÄ‚îÄ\n",
    "from detectron2.data import DatasetCatalog\n",
    "\n",
    "for subset_name, paths in AGAR_DATASETS.items():\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        ds_name = f\"{subset_name}_{split}\"\n",
    "        if ds_name not in DatasetCatalog.list():\n",
    "            register_coco_instances(ds_name, {}, paths[split], AGAR_IMG_DIR)\n",
    "            print(f\"Registered: {ds_name}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Register Roboflow datasets ‚îÄ‚îÄ\n",
    "robo = ROBOFLOW_DATASETS['curated']\n",
    "for split, dir_key in [('train', 'train_dir'), ('valid', 'val_dir'), ('test', 'test_dir')]:\n",
    "    ds_name = f\"roboflow_{split}\"\n",
    "    if ds_name not in DatasetCatalog.list():\n",
    "        register_coco_instances(ds_name, {}, robo[split], robo[dir_key])\n",
    "        print(f\"Registered: {ds_name}\")\n",
    "\n",
    "print(f\"\\nTotal registered datasets: {len(DatasetCatalog.list())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6349935",
   "metadata": {},
   "source": [
    "## Define inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_and_save(\n",
    "    model_dir: str,\n",
    "    config_file: str,\n",
    "    test_dataset_name: str,\n",
    "    num_classes: int = 3,\n",
    "    score_thresh: float = 0.5,\n",
    "    max_dets: int = 100,\n",
    "    output_subfolder: str = \"test\",\n",
    "    force_rerun: bool = False,\n",
    "):\n",
    "    \"\"\"Load a trained model and run COCO evaluation on the test set.\n",
    "    \n",
    "    Saves coco_instances_results.json to {model_dir}/{output_subfolder}/\n",
    "    \n",
    "    Returns:\n",
    "        dict: COCO evaluation results, or None if skipped.\n",
    "    \"\"\"\n",
    "    weights_path = os.path.join(model_dir, \"model_final.pth\")\n",
    "    output_dir = os.path.join(model_dir, output_subfolder)\n",
    "    results_file = os.path.join(output_dir, \"coco_instances_results.json\")\n",
    "    \n",
    "    # Check if weights exist\n",
    "    if not os.path.exists(weights_path):\n",
    "        print(f\"  ‚ö†Ô∏è SKIP: model_final.pth not found at {weights_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Skip if already done (unless force_rerun)\n",
    "    if os.path.exists(results_file) and not force_rerun:\n",
    "        print(f\"  ‚úÖ Already exists: {results_file}\")\n",
    "        # Load and return existing results summary\n",
    "        return {\"status\": \"cached\", \"path\": results_file}\n",
    "    \n",
    "    # Build config\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_file))\n",
    "    cfg.DATASETS.TEST = (test_dataset_name,)\n",
    "    cfg.MODEL.WEIGHTS = weights_path\n",
    "    cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "    cfg.TEST.DETECTIONS_PER_IMAGE = max_dets\n",
    "    \n",
    "    # Set num_classes based on architecture\n",
    "    if 'retinanet' in config_file.lower():\n",
    "        cfg.MODEL.RETINANET.NUM_CLASSES = num_classes\n",
    "        cfg.MODEL.RETINANET.SCORE_THRESH_TEST = score_thresh\n",
    "    else:\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = score_thresh\n",
    "    \n",
    "    cfg.OUTPUT_DIR = output_dir\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Run inference\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    evaluator = COCOEvaluator(\n",
    "        test_dataset_name, output_dir=output_dir, max_dets_per_image=max_dets\n",
    "    )\n",
    "    val_loader = build_detection_test_loader(cfg, test_dataset_name)\n",
    "    results = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "    \n",
    "    print(f\"  üìä AP={results['bbox']['AP']:.1f}  AP50={results['bbox']['AP50']:.1f}\")\n",
    "    \n",
    "    # Free GPU memory\n",
    "    del predictor\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ca5430",
   "metadata": {},
   "source": [
    "## Map model keys ‚Üí architecture config files + test set names\n",
    "\n",
    "We need to know which Detectron2 config file and test dataset corresponds to each trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3733e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arch_config(model_key: str) -> str:\n",
    "    \"\"\"Map a trained model key to its Detectron2 config file.\"\"\"\n",
    "    # Extract architecture from model key\n",
    "    key_lower = model_key.lower()\n",
    "    if 'mask_rcnn_r101' in key_lower:\n",
    "        return MODELS['mask_rcnn_R101']\n",
    "    elif 'mask_rcnn_r50' in key_lower:\n",
    "        return MODELS['mask_rcnn_R50']\n",
    "    elif 'retinanet_r101' in key_lower or 'retinanet_r_101' in key_lower:\n",
    "        return MODELS['retinanet_R101']\n",
    "    elif 'retinanet_r50' in key_lower or 'retinanet_r_50' in key_lower:\n",
    "        return MODELS['retinanet_R50']\n",
    "    elif 'faster_rcnn_r101' in key_lower or 'faster_r101' in key_lower:\n",
    "        return MODELS['faster_rcnn_R101']\n",
    "    elif 'faster_rcnn_r50' in key_lower or 'faster_r50' in key_lower:\n",
    "        return MODELS['faster_rcnn_R50']\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot determine architecture for model key: {model_key}\")\n",
    "\n",
    "\n",
    "def get_test_dataset(model_key: str, source: str = 'agar') -> str:\n",
    "    \"\"\"Map a trained model key to its test dataset name.\"\"\"\n",
    "    if source == 'roboflow':\n",
    "        return 'roboflow_test'\n",
    "    # Extract subset from key (e.g., 'bright_faster_rcnn_R50' -> 'bright')\n",
    "    for subset in ['total', 'bright', 'dark', 'vague', 'lowres']:\n",
    "        if model_key.startswith(subset):\n",
    "            return f\"{subset}_test\"\n",
    "    raise ValueError(f\"Cannot determine test dataset for model key: {model_key}\")\n",
    "\n",
    "\n",
    "def get_num_classes(source: str) -> int:\n",
    "    \"\"\"AGAR has 3 classes, Roboflow has 4.\"\"\"\n",
    "    return 4 if source == 'roboflow' else 3\n",
    "\n",
    "\n",
    "# Verify mapping works\n",
    "print(\"=== AGAR Models ===\")\n",
    "for key in list(AGAR_TRAINED_MODELS.keys())[:3]:\n",
    "    print(f\"  {key} ‚Üí arch={get_arch_config(key)}, test={get_test_dataset(key)}\")\n",
    "\n",
    "print(\"\\n=== Roboflow Models ===\")\n",
    "for key in list(ROBOFLOW_TRAINED_MODELS.keys())[:3]:\n",
    "    print(f\"  {key} ‚Üí arch={get_arch_config(key)}, test={get_test_dataset(key, 'roboflow')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb9fb3",
   "metadata": {},
   "source": [
    "## Run batch inference on all AGAR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e974f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_RERUN = False  # Set True to re-generate all predictions\n",
    "\n",
    "agar_results = {}\n",
    "failed = []\n",
    "\n",
    "print(f\"Running inference on {len(AGAR_TRAINED_MODELS)} AGAR models...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, (model_key, model_dir) in enumerate(AGAR_TRAINED_MODELS.items()):\n",
    "    print(f\"\\n[{i+1}/{len(AGAR_TRAINED_MODELS)}] {model_key}\")\n",
    "    print(f\"  Dir: {model_dir}\")\n",
    "    \n",
    "    try:\n",
    "        arch_config = get_arch_config(model_key)\n",
    "        test_ds = get_test_dataset(model_key, 'agar')\n",
    "        num_classes = get_num_classes('agar')\n",
    "        \n",
    "        result = run_inference_and_save(\n",
    "            model_dir=model_dir,\n",
    "            config_file=arch_config,\n",
    "            test_dataset_name=test_ds,\n",
    "            num_classes=num_classes,\n",
    "            force_rerun=FORCE_RERUN,\n",
    "        )\n",
    "        agar_results[model_key] = result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå ERROR: {e}\")\n",
    "        failed.append((model_key, str(e)))\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Completed: {len(agar_results)}/{len(AGAR_TRAINED_MODELS)}\")\n",
    "if failed:\n",
    "    print(f\"Failed: {len(failed)}\")\n",
    "    for key, err in failed:\n",
    "        print(f\"  - {key}: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae2f3b",
   "metadata": {},
   "source": [
    "## Run batch inference on all Roboflow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43083b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "robo_results = {}\n",
    "robo_failed = []\n",
    "\n",
    "print(f\"Running inference on {len(ROBOFLOW_TRAINED_MODELS)} Roboflow models...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, (model_key, model_dir) in enumerate(ROBOFLOW_TRAINED_MODELS.items()):\n",
    "    print(f\"\\n[{i+1}/{len(ROBOFLOW_TRAINED_MODELS)}] {model_key}\")\n",
    "    print(f\"  Dir: {model_dir}\")\n",
    "    \n",
    "    try:\n",
    "        arch_config = get_arch_config(model_key)\n",
    "        test_ds = get_test_dataset(model_key, 'roboflow')\n",
    "        num_classes = get_num_classes('roboflow')\n",
    "        \n",
    "        result = run_inference_and_save(\n",
    "            model_dir=model_dir,\n",
    "            config_file=arch_config,\n",
    "            test_dataset_name=test_ds,\n",
    "            num_classes=num_classes,\n",
    "            force_rerun=FORCE_RERUN,\n",
    "        )\n",
    "        robo_results[model_key] = result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå ERROR: {e}\")\n",
    "        robo_failed.append((model_key, str(e)))\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Completed: {len(robo_results)}/{len(ROBOFLOW_TRAINED_MODELS)}\")\n",
    "if robo_failed:\n",
    "    print(f\"Failed: {len(robo_failed)}\")\n",
    "    for key, err in robo_failed:\n",
    "        print(f\"  - {key}: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5098c",
   "metadata": {},
   "source": [
    "## Verify all prediction files exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_predictions_path\n",
    "\n",
    "print(\"=== Prediction file status ===\")\n",
    "print(\"\\n--- AGAR Models ---\")\n",
    "for key in AGAR_TRAINED_MODELS:\n",
    "    path = get_predictions_path(key, source='agar', subfolder='test')\n",
    "    exists = os.path.exists(path)\n",
    "    status = '‚úÖ' if exists else '‚ùå'\n",
    "    size = f\"{os.path.getsize(path)/1024:.0f}KB\" if exists else 'missing'\n",
    "    print(f\"  {status} {key}: {size}\")\n",
    "\n",
    "print(\"\\n--- Roboflow Models ---\")\n",
    "for key in ROBOFLOW_TRAINED_MODELS:\n",
    "    path = get_predictions_path(key, source='roboflow', subfolder='test')\n",
    "    exists = os.path.exists(path)\n",
    "    status = '‚úÖ' if exists else '‚ùå'\n",
    "    size = f\"{os.path.getsize(path)/1024:.0f}KB\" if exists else 'missing'\n",
    "    print(f\"  {status} {key}: {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c964111",
   "metadata": {},
   "source": [
    "## Summary table of all test-set AP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7eef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results into a summary DataFrame\n",
    "summary_rows = []\n",
    "\n",
    "for key, result in {**agar_results, **robo_results}.items():\n",
    "    if result and isinstance(result, dict) and 'bbox' in result:\n",
    "        bbox = result['bbox']\n",
    "        summary_rows.append({\n",
    "            'Model': key,\n",
    "            'AP': bbox.get('AP', None),\n",
    "            'AP50': bbox.get('AP50', None),\n",
    "            'AP75': bbox.get('AP75', None),\n",
    "            'APs': bbox.get('APs', None),\n",
    "            'APm': bbox.get('APm', None),\n",
    "            'APl': bbox.get('APl', None),\n",
    "        })\n",
    "\n",
    "if summary_rows:\n",
    "    import pandas as pd\n",
    "    df_summary = pd.DataFrame(summary_rows)\n",
    "    df_summary = df_summary.sort_values('AP50', ascending=False)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = os.path.join(config.RESULTS_DIR, 'all_models_test_ap.csv')\n",
    "    os.makedirs(config.RESULTS_DIR, exist_ok=True)\n",
    "    df_summary.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved summary to: {csv_path}\")\n",
    "    \n",
    "    display(df_summary.style.format(precision=1))\n",
    "else:\n",
    "    print(\"No new results generated (all cached). Set FORCE_RERUN=True to re-evaluate.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
