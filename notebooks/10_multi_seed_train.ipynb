{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb498ec",
   "metadata": {},
   "source": [
    "# 10 — Multi-Seed Training (Variance Quantification)\n",
    "\n",
    "**Purpose:** Retrain the best-performing model with multiple random seeds\n",
    "to quantify training stochasticity and report mean ± std AP.\n",
    "\n",
    "**Plan:** 3 seeds × 2 models = **6 runs total** (~12-18 hours on Colab T4)\n",
    "- Best model: Faster R-CNN R101 on `total` dataset\n",
    "- Baseline: Faster R-CNN R50 on `total` dataset\n",
    "\n",
    "**Training config matches original notebook exactly:**\n",
    "- `batch_size = 8`\n",
    "- `iterations = 2800` (hardcoded, not epochs × images / batch)\n",
    "- `base_lr = 0.005`, `momentum = 0.9`, `weight_decay = 0.0005`\n",
    "- `steps = [840]` (single LR decay at 30% = 3×2800/10)\n",
    "- `warmup_iters = min(1000, save_checkpoint)`\n",
    "- `ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512`\n",
    "- `FILTER_EMPTY_ANNOTATIONS = False`\n",
    "- `num_classes = 3`\n",
    "\n",
    "**Run on:** Google Colab with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Mount Google Drive (for data and model weights)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Clone project repo (code, config, utils)\n",
    "REPO_URL = \"https://github.com/jozedu/deep-microbiology-colony-detection.git\"\n",
    "REPO_DIR = \"/content/deep-microbiology-colony-detection\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df482292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install detectron2 if needed\n",
    "try:\n",
    "    import detectron2\n",
    "except ImportError:\n",
    "    !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog\n",
    "\n",
    "import config\n",
    "from config import (\n",
    "    AGAR_IMG_DIR, OUTPUTS_DIR, MODELS, AGAR_DATASETS,\n",
    ")\n",
    "from utils.training import MyTrainer\n",
    "\n",
    "print(f\"Detectron2 version: {detectron2.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the 'total' dataset (used for both models)\n",
    "total_paths = AGAR_DATASETS['total']\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    ds_name = f\"total_{split}\"\n",
    "    if ds_name not in DatasetCatalog.list():\n",
    "        register_coco_instances(ds_name, {}, total_paths[split], AGAR_IMG_DIR)\n",
    "        print(f\"Registered: {ds_name}\")\n",
    "\n",
    "# Count training images (for logging only)\n",
    "with open(total_paths['train'], 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "NUM_TRAIN_IMAGES = len(train_data['images'])\n",
    "print(f\"Training images: {NUM_TRAIN_IMAGES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e7f03",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "These values **exactly match** the original training in `detectron2.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8473db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Experiment configuration ──\n",
    "SEEDS = [42, 123, 456]\n",
    "\n",
    "EXPERIMENTS = [\n",
    "    {\n",
    "        \"name\": \"total_faster_rcnn_R101\",\n",
    "        \"config_file\": MODELS[\"faster_rcnn_R101\"],\n",
    "        \"label\": \"Faster R-CNN R101 (best)\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"total_faster_rcnn_R50\",\n",
    "        \"config_file\": MODELS[\"faster_rcnn_R50\"],\n",
    "        \"label\": \"Faster R-CNN R50 (baseline)\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# ── Training hyperparameters (exactly as in original notebook) ──\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 10\n",
    "ITERATIONS = 2800  # hardcoded in original notebook\n",
    "SAVE_CHECKPOINT = ITERATIONS // NUM_EPOCHS  # 280\n",
    "STEPS = [int((3 * ITERATIONS) / NUM_EPOCHS)]  # [840] — single LR decay\n",
    "BASE_LR = 0.005\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0005\n",
    "WARMUP_ITERS = min(1000, SAVE_CHECKPOINT)\n",
    "WARMUP_FACTOR = 1.0 / 1000\n",
    "ROI_BATCH_SIZE = 512\n",
    "NUM_CLASSES = 3\n",
    "MAX_DETS = 100\n",
    "SCORE_THRESH = 0.5\n",
    "\n",
    "TRAIN_NAME = \"total_train\"\n",
    "VAL_NAME = \"total_val\"\n",
    "TEST_NAME = \"total_test\"\n",
    "\n",
    "print(f\"Seeds: {SEEDS}\")\n",
    "print(f\"Iterations: {ITERATIONS}\")\n",
    "print(f\"LR steps: {STEPS}\")\n",
    "print(f\"Checkpoint every: {SAVE_CHECKPOINT} iters\")\n",
    "print(f\"Warmup: {WARMUP_ITERS} iters\")\n",
    "print(f\"Total runs: {len(SEEDS) * len(EXPERIMENTS)} = {len(SEEDS)} seeds × {len(EXPERIMENTS)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386682d",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cfg(config_file: str, seed: int, output_dir: str) -> object:\n",
    "    \"\"\"Build a Detectron2 config matching original training exactly.\"\"\"\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_file))\n",
    "    \n",
    "    # Datasets\n",
    "    cfg.DATASETS.TRAIN = (TRAIN_NAME,)\n",
    "    cfg.DATASETS.TEST = (VAL_NAME,)\n",
    "    \n",
    "    # Data loader\n",
    "    cfg.DATALOADER.NUM_WORKERS = 4\n",
    "    cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "    \n",
    "    # Weights from model zoo (COCO pretrained)\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_file)\n",
    "    \n",
    "    # Solver — matches original notebook exactly\n",
    "    cfg.SOLVER.IMS_PER_BATCH = BATCH_SIZE\n",
    "    cfg.SOLVER.BASE_LR = BASE_LR\n",
    "    cfg.SOLVER.MOMENTUM = MOMENTUM\n",
    "    cfg.SOLVER.WEIGHT_DECAY = WEIGHT_DECAY\n",
    "    cfg.SOLVER.MAX_ITER = ITERATIONS\n",
    "    cfg.SOLVER.STEPS = tuple(STEPS)\n",
    "    cfg.SOLVER.WARMUP_FACTOR = WARMUP_FACTOR\n",
    "    cfg.SOLVER.WARMUP_ITERS = WARMUP_ITERS\n",
    "    cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
    "    \n",
    "    # Model head\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = ROI_BATCH_SIZE\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESH\n",
    "    cfg.TEST.DETECTIONS_PER_IMAGE = MAX_DETS\n",
    "    \n",
    "    # Checkpointing\n",
    "    cfg.SOLVER.CHECKPOINT_PERIOD = SAVE_CHECKPOINT\n",
    "    cfg.TEST.EVAL_PERIOD = SAVE_CHECKPOINT\n",
    "    \n",
    "    # SEED — the key addition for this experiment\n",
    "    cfg.SEED = seed\n",
    "    \n",
    "    # Output\n",
    "    cfg.OUTPUT_DIR = output_dir\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "\n",
    "def train_and_evaluate(config_file: str, seed: int, run_name: str):\n",
    "    \"\"\"Train a model and evaluate on the test set. Returns results dict.\"\"\"\n",
    "    current_time = datetime.datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "    output_dir = os.path.join(\n",
    "        OUTPUTS_DIR, f\"seed{seed}_{run_name}_{current_time}\"\n",
    "    )\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {run_name} | Seed: {seed}\")\n",
    "    print(f\"Output: {output_dir}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Set all random seeds for reproducibility\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Build config\n",
    "    cfg = build_cfg(config_file, seed, output_dir)\n",
    "    \n",
    "    # Save the full resolved config BEFORE training\n",
    "    config_path = os.path.join(output_dir, \"full_config.yaml\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(cfg.dump())\n",
    "    print(f\"Saved config to: {config_path}\")\n",
    "    \n",
    "    # Train\n",
    "    trainer = MyTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate on TEST set\n",
    "    print(f\"\\nEvaluating on test set...\")\n",
    "    cfg.DATASETS.TEST = (TEST_NAME,)\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(output_dir, \"model_final.pth\")\n",
    "    \n",
    "    test_output = os.path.join(output_dir, \"test\")\n",
    "    os.makedirs(test_output, exist_ok=True)\n",
    "    \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    evaluator = COCOEvaluator(\n",
    "        TEST_NAME, output_dir=test_output, max_dets_per_image=MAX_DETS\n",
    "    )\n",
    "    val_loader = build_detection_test_loader(cfg, TEST_NAME)\n",
    "    results = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "    \n",
    "    # Save results\n",
    "    results_path = os.path.join(output_dir, \"test_results.json\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"AP={results['bbox']['AP']:.1f}  AP50={results['bbox']['AP50']:.1f}\")\n",
    "    \n",
    "    # Clean up GPU memory\n",
    "    del trainer, predictor\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\n",
    "        \"seed\": seed,\n",
    "        \"model\": run_name,\n",
    "        \"output_dir\": output_dir,\n",
    "        \"AP\": results['bbox']['AP'],\n",
    "        \"AP50\": results['bbox']['AP50'],\n",
    "        \"AP75\": results['bbox']['AP75'],\n",
    "        \"APs\": results['bbox']['APs'],\n",
    "        \"APm\": results['bbox']['APm'],\n",
    "        \"APl\": results['bbox']['APl'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Run all experiments ──\n",
    "all_results = []\n",
    "\n",
    "for exp in EXPERIMENTS:\n",
    "    for seed in SEEDS:\n",
    "        result = train_and_evaluate(\n",
    "            config_file=exp[\"config_file\"],\n",
    "            seed=seed,\n",
    "            run_name=exp[\"name\"],\n",
    "        )\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Save intermediate results (in case Colab disconnects)\n",
    "        intermediate_path = os.path.join(config.RESULTS_DIR, \"multi_seed_results_partial.json\")\n",
    "        os.makedirs(config.RESULTS_DIR, exist_ok=True)\n",
    "        with open(intermediate_path, 'w') as f:\n",
    "            json.dump(all_results, f, indent=2)\n",
    "        print(f\"Saved intermediate results to: {intermediate_path}\")\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(f\"ALL EXPERIMENTS COMPLETE ({len(all_results)} runs)\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef19e1",
   "metadata": {},
   "source": [
    "## Results: Mean ± Std across seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcacd22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Summary: mean ± std per model\n",
    "metrics = ['AP', 'AP50', 'AP75', 'APs', 'APm', 'APl']\n",
    "\n",
    "summary = df.groupby('model')[metrics].agg(['mean', 'std'])\n",
    "summary.columns = [f\"{m}_{s}\" for m, s in summary.columns]\n",
    "\n",
    "# Format nicely\n",
    "print(\"\\n=== Multi-Seed Results (mean ± std across 3 seeds) ===\")\n",
    "print()\n",
    "for model in df['model'].unique():\n",
    "    model_df = df[df['model'] == model]\n",
    "    print(f\"\\n{model}:\")\n",
    "    for m in metrics:\n",
    "        mean_val = model_df[m].mean()\n",
    "        std_val = model_df[m].std()\n",
    "        values = model_df[m].tolist()\n",
    "        print(f\"  {m}: {mean_val:.1f} ± {std_val:.1f}  (seeds: {[f'{v:.1f}' for v in values]})\")\n",
    "\n",
    "# Save final results\n",
    "final_path = os.path.join(config.RESULTS_DIR, \"multi_seed_results.json\")\n",
    "with open(final_path, 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "csv_path = os.path.join(config.RESULTS_DIR, \"multi_seed_results.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\nSaved to: {final_path}\")\n",
    "print(f\"Saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7caf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualization: bar chart with error bars ──\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, metric in zip(axes, ['AP', 'AP50', 'AP75']):\n",
    "    models = df['model'].unique()\n",
    "    means = [df[df['model'] == m][metric].mean() for m in models]\n",
    "    stds = [df[df['model'] == m][metric].std() for m in models]\n",
    "    \n",
    "    bars = ax.bar(range(len(models)), means, yerr=stds, capsize=5,\n",
    "                  color=['#3878a2', '#e2a83e'], edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Add individual seed points\n",
    "    for i, m in enumerate(models):\n",
    "        values = df[df['model'] == m][metric].values\n",
    "        ax.scatter([i] * len(values), values, color='black', s=30, zorder=5)\n",
    "    \n",
    "    ax.set_xticks(range(len(models)))\n",
    "    ax.set_xticklabels([m.replace('total_', '') for m in models], rotation=20, ha='right')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'{metric} across 3 seeds')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_path = os.path.join(config.RESULTS_DIR, 'multi_seed_variance.png')\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved plot to: {plot_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a6d7a",
   "metadata": {},
   "source": [
    "## Update config.py with new model paths\n",
    "\n",
    "After training, add the new model directories to `config.py` manually, e.g.:\n",
    "\n",
    "```python\n",
    "MULTI_SEED_MODELS = {\n",
    "    \"total_faster_rcnn_R101_seed42\":  os.path.join(OUTPUTS_DIR, \"seed42_total_faster_rcnn_R101_...\"),\n",
    "    \"total_faster_rcnn_R101_seed123\": os.path.join(OUTPUTS_DIR, \"seed123_total_faster_rcnn_R101_...\"),\n",
    "    \"total_faster_rcnn_R101_seed456\": os.path.join(OUTPUTS_DIR, \"seed456_total_faster_rcnn_R101_...\"),\n",
    "    # ... etc\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
