{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80718bd",
   "metadata": {},
   "source": [
    "# 3. Model Training\n",
    "\n",
    "This notebook trains Detectron2 object detection models for microbial colony detection.\n",
    "\n",
    "**Supports all experimental configurations:**\n",
    "- Part 1: AGAR dataset (5 subsets Ã— 4 models = 20 runs)\n",
    "- Part 2: Curated/Roboflow dataset (4 models)\n",
    "- Transfer learning from pre-trained AGAR models\n",
    "\n",
    "**Configuration:** Change the parameters in Section 3.1 to select the dataset, model, and training mode.\n",
    "\n",
    "**Prerequisites:** Run `1_setup.ipynb` and `2_data_exploration.ipynb` first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17052502",
   "metadata": {},
   "source": [
    "## 3.1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc42a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "import config\n",
    "from utils.training import MyTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== CONFIGURE YOUR EXPERIMENT =====================\n",
    "\n",
    "# --- Dataset ---\n",
    "DATASET_SOURCE = \"agar\"       # 'agar' or 'roboflow'\n",
    "SUBSET = \"total\"              # For AGAR: 'total', 'bright', 'dark', 'vague', 'lowres'\n",
    "\n",
    "# --- Model ---\n",
    "MODEL_KEY = \"faster_rcnn_R50\"  # See config.MODELS for options:\n",
    "                               # 'faster_rcnn_R50', 'faster_rcnn_R101',\n",
    "                               # 'retinanet_R50', 'retinanet_R101',\n",
    "                               # 'mask_rcnn_R50', 'mask_rcnn_R101'\n",
    "\n",
    "# --- Training mode ---\n",
    "USE_TRANSFER_LEARNING = False  # If True, set TRANSFER_WEIGHTS below\n",
    "TRANSFER_WEIGHTS = None        # Path to .pth file, e.g.:\n",
    "# TRANSFER_WEIGHTS = config.get_model_weights(\"total_faster_rcnn_R101\", \"agar\")\n",
    "# TRANSFER_WEIGHTS = config.get_model_weights(\"total_retinanet_R50\", \"agar\")\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 10                # AGAR: 10, Roboflow: 100\n",
    "BASE_LR = 0.005\n",
    "NUM_CLASSES = 3                # AGAR: 3, Roboflow: 4 (3 + background)\n",
    "\n",
    "# --- Reproducibility ---\n",
    "RANDOM_SEED = 42               # Fixed seed for deterministic training\n",
    "\n",
    "# ====================================================================\n",
    "\n",
    "print(f\"Experiment: {DATASET_SOURCE}/{SUBSET} | Model: {MODEL_KEY}\")\n",
    "print(f\"Transfer learning: {USE_TRANSFER_LEARNING}\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}, Batch: {BATCH_SIZE}, LR: {BASE_LR}\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b845d6",
   "metadata": {},
   "source": [
    "## 3.2 Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b820f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET_SOURCE == \"agar\":\n",
    "    dataset = config.AGAR_DATASETS[SUBSET]\n",
    "    train_path = dataset[\"train\"]\n",
    "    val_path = dataset[\"val\"]\n",
    "    test_path = dataset[\"test\"]\n",
    "    img_dir_train = img_dir_val = img_dir_test = config.AGAR_IMG_DIR\n",
    "    train_name = f\"{SUBSET}_train\"\n",
    "    val_name = f\"{SUBSET}_val\"\n",
    "    test_name = f\"{SUBSET}_test\"\n",
    "    dataset_label = f\"{SUBSET}_100\"\n",
    "\n",
    "elif DATASET_SOURCE == \"roboflow\":\n",
    "    dataset = config.ROBOFLOW_DATASETS[\"curated\"]\n",
    "    train_path = dataset[\"train\"]\n",
    "    val_path = dataset[\"val\"]\n",
    "    test_path = dataset[\"test\"]\n",
    "    img_dir_train = dataset[\"train_dir\"]\n",
    "    img_dir_val = dataset[\"val_dir\"]\n",
    "    img_dir_test = dataset[\"test_dir\"]\n",
    "    train_name = \"robo_train\"\n",
    "    val_name = \"robo_val\"\n",
    "    test_name = \"robo_test\"\n",
    "    dataset_label = \"final_noaugm\"\n",
    "\n",
    "# Register datasets (safe to re-run)\n",
    "for name, ann_path, img_dir in [\n",
    "    (train_name, train_path, img_dir_train),\n",
    "    (val_name, val_path, img_dir_val),\n",
    "    (test_name, test_path, img_dir_test),\n",
    "]:\n",
    "    if name in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(name)\n",
    "        MetadataCatalog.remove(name)\n",
    "    register_coco_instances(name, {}, ann_path, img_dir)\n",
    "\n",
    "print(f\"Datasets registered: {train_name}, {val_name}, {test_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2533f3",
   "metadata": {},
   "source": [
    "## 3.3 Compute Training Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "num_train_images = len(data['images'])\n",
    "iterations = NUM_EPOCHS * num_train_images // BATCH_SIZE\n",
    "checkpoint_period = num_train_images // BATCH_SIZE  # once per epoch\n",
    "lr_decay_step = int(0.7 * iterations)\n",
    "\n",
    "print(f\"Training images: {num_train_images}\")\n",
    "print(f\"Total iterations: {iterations}\")\n",
    "print(f\"Checkpoint every: {checkpoint_period} iterations (= 1 epoch)\")\n",
    "print(f\"LR decay at iteration: {lr_decay_step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32348a10",
   "metadata": {},
   "source": [
    "## 3.4 Build Detectron2 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ef6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = config.MODELS[MODEL_KEY]\n",
    "model_name = os.path.splitext(os.path.basename(config_file))[0]\n",
    "\n",
    "# Output directory with timestamp\n",
    "current_time = datetime.datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "transfer_tag = \"_transferlearn\" if USE_TRANSFER_LEARNING else \"\"\n",
    "output_dir = os.path.join(\n",
    "    config.OUTPUTS_DIR,\n",
    "    f\"{dataset_label}{transfer_tag}_{model_name}_{current_time}\"\n",
    ")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Build config\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(config_file))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (train_name,)\n",
    "cfg.DATASETS.TEST = (val_name,)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "\n",
    "# Reproducibility: set random seed\n",
    "cfg.SEED = RANDOM_SEED\n",
    "\n",
    "# Weights: transfer learning or model zoo\n",
    "if USE_TRANSFER_LEARNING and TRANSFER_WEIGHTS:\n",
    "    cfg.MODEL.WEIGHTS = TRANSFER_WEIGHTS\n",
    "    print(f\"Transfer learning from: {TRANSFER_WEIGHTS}\")\n",
    "else:\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_file)\n",
    "    print(f\"Initializing from model zoo: {config_file}\")\n",
    "\n",
    "# Optimizer\n",
    "cfg.SOLVER.IMS_PER_BATCH = BATCH_SIZE\n",
    "cfg.SOLVER.BASE_LR = BASE_LR\n",
    "cfg.SOLVER.MOMENTUM = 0.9\n",
    "cfg.SOLVER.WEIGHT_DECAY = 0.0005\n",
    "cfg.SOLVER.MAX_ITER = iterations\n",
    "cfg.SOLVER.STEPS = (lr_decay_step,)\n",
    "\n",
    "# Warmup\n",
    "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000\n",
    "cfg.SOLVER.WARMUP_ITERS = min(1000, checkpoint_period)\n",
    "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
    "\n",
    "# Detection head\n",
    "if config.is_retinanet(MODEL_KEY):\n",
    "    cfg.MODEL.RETINANET.NUM_CLASSES = NUM_CLASSES\n",
    "else:\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "\n",
    "# Checkpointing & evaluation\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = checkpoint_period\n",
    "cfg.TEST.EVAL_PERIOD = checkpoint_period\n",
    "cfg.OUTPUT_DIR = output_dir\n",
    "\n",
    "# Save full resolved config for reproducibility\n",
    "config_yaml_path = os.path.join(output_dir, \"full_config.yaml\")\n",
    "with open(config_yaml_path, \"w\") as f:\n",
    "    f.write(cfg.dump())\n",
    "print(f\"Full config saved to: {config_yaml_path}\")\n",
    "\n",
    "print(f\"\\nOutput directory: {output_dir}\")\n",
    "print(f\"Config file: {config_file}\")\n",
    "print(f\"Num classes: {NUM_CLASSES}\")\n",
    "print(f\"Seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6846ae",
   "metadata": {},
   "source": [
    "## 3.5 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93715a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd7756",
   "metadata": {},
   "source": [
    "## 3.6 Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a73d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import plot_training_curves\n",
    "\n",
    "metrics_path = os.path.join(output_dir, \"metrics.json\")\n",
    "plot_save_path = os.path.join(output_dir, \"training_curves.png\")\n",
    "\n",
    "plot_training_curves(metrics_path, save_path=plot_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e5b24",
   "metadata": {},
   "source": [
    "## 3.7 TensorBoard (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {output_dir}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
